{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://i.ytimg.com/vi/Wm8ftqDZUVk/maxresdefault.jpg\" alt=\"FIUBA\" width=\"25%\"/>\n",
    "  </p>\n",
    "  \n",
    "# **Trabajo Pr√°ctico 2: Cr√≠ticas Cinematogr√°ficas**\n",
    "### **Grupo**: 11 - Los Pandas üêº\n",
    "### **Cuatrimestre**: 2¬∫C 2023\n",
    "### **Corrector**: Mateo Suster\n",
    "### **Integrantes**:\n",
    "- ### 106861 - Labollita, Francisco\n",
    "- ### 102312 - Mundani Vegega, Ezequiel\n",
    "- ###  97263 - Otegui, Mat√≠as I√±aki"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaci√≥n del bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '00000' '00000000000' '0000000000001' '00000001' '00001'\n",
      " '0001' '00015' '000dm' '001' '002' '003830' '006' '0069' '007' '0079'\n",
      " '007the' '0080' '0083']\n",
      "['antisocial' 'antisociales' 'antiste' 'antisunciados' 'antit'\n",
      " 'antitabaco' 'antitanque' 'antiterroristas' 'antitesis' 'antitetico'\n",
      " 'antithesis' 'antithetical' 'antitica' 'antitm' 'antitreideros'\n",
      " 'antitrust' 'antivirus' 'antiwar' 'antm' 'antoina']\n",
      "['zyuranger' 'zz' 'zzzz' 'zzzzip' 'zzzzz' 'zzzzzzzzz' 'zzzzzzzzzzzzzz'\n",
      " 'zzzzzzzzzzzzzzzzz' 'zzzzzzzzzzzzzzzzzzzz' 'zzzzzzzzzzzzzzzzzzzzz'\n",
      " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz'\n",
      " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz' '√¶bler' '√¶on' '√¶sthetic'\n",
      " '√∏stbye' '√æo' '√æorleifsson' '◊ô◊í◊ê◊ú' '◊õ◊®◊û◊ï◊ü']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents='unicode')\n",
    "vectorizer.fit_transform(reviews['review_es'])\n",
    "\n",
    "# Primeros 20 elementos\n",
    "print(vectorizer.get_feature_names_out()[:20])\n",
    "# Elementos del medio\n",
    "print(vectorizer.get_feature_names_out()[10000:10020])\n",
    "# √öltimos 20 elementos\n",
    "print(vectorizer.get_feature_names_out()[-20:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que varias \"palabras\" ser√°n n√∫meros, algunas tendr√°n s√≠mbolos no pertenecientes al alfabeto espa√±ol y tambi√©n se comprueba que est√°n palabras espa√±olas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering del bag of words\n",
    "\n",
    "En primer lugar, siendo que todas las palabras que inician una oraci√≥n empiezan en may√∫scula, se har√° que todas las letras de palabras con una sola may√∫scula sean transformadas a min√∫sculas. De tal manera que en el siguiente ejemplo, las dos variaciones de hermosa sean una misma palabra: \"Hermosa pel√≠cula\" y \"Esta pel√≠cula es hermosa\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerTotal = CountVectorizer(strip_accents='unicode')\n",
    "matrizApariciones = vectorizerTotal.fit_transform(reviews['review_es'])\n",
    "matrizSiAparece = vectorizerTotal.fit_transform(reviews['review_es'])\n",
    "\n",
    "# Creo un vectorizador para cr√≠ticas positivas y otro para cr√≠ticas negativas\n",
    "vectorizerPos = CountVectorizer(strip_accents='unicode')\n",
    "reviewsPos = reviews[reviews['sentimiento'] == 'positivo']\n",
    "\n",
    "vectorizerNeg = CountVectorizer(strip_accents='unicode')\n",
    "reviewsNeg = reviews[reviews['sentimiento'] == 'negativo']\n",
    "\n",
    "# Armar matriz de apariciones totales y de si aparece para reviews solo positivas y negativas\n",
    "matrizAparicionesPos = vectorizerPos.fit_transform(reviewsPos['review_es'])\n",
    "matrizSiAparecePos = vectorizerPos.fit_transform(reviewsPos['review_es'])\n",
    "matrizAparicionesNeg = vectorizerNeg.fit_transform(reviewsNeg['review_es'])\n",
    "matrizSiApareceNeg = vectorizerNeg.fit_transform(reviewsNeg['review_es'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se convierte el int64 en uint8 para que ocupe menos espacio en memoria\n",
    "matrizSiAparece = matrizSiAparece.astype('uint8').toarray()\n",
    "matrizSiAparecePos = matrizSiAparecePos.astype('uint8').toarray()\n",
    "matrizSiApareceNeg = matrizSiApareceNeg.astype('uint8').toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizSiAparece[matrizSiAparece > 0] = 1\n",
    "matrizSiAparecePos[matrizSiAparecePos > 0] = 1\n",
    "matrizSiApareceNeg[matrizSiApareceNeg > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Apariciones</th>\n",
       "      <th>Tasa de aparici√≥n</th>\n",
       "      <th>Tasa de aparici√≥n positivas</th>\n",
       "      <th>Tasa de aparici√≥n negativas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>213</td>\n",
       "      <td>0.00368</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>0.00420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>613</td>\n",
       "      <td>0.00896</td>\n",
       "      <td>0.00780</td>\n",
       "      <td>0.01012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000dm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>003830</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>007</td>\n",
       "      <td>73</td>\n",
       "      <td>0.00086</td>\n",
       "      <td>0.00136</td>\n",
       "      <td>0.00036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0079</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>007the</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0080</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0083</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Palabra  Apariciones  Tasa de aparici√≥n  \\\n",
       "0              00          213            0.00368   \n",
       "1             000          613            0.00896   \n",
       "2           00000            4            0.00004   \n",
       "3     00000000000            2            0.00002   \n",
       "4   0000000000001            1            0.00002   \n",
       "5        00000001            1            0.00002   \n",
       "6           00001            2            0.00004   \n",
       "7            0001            1            0.00002   \n",
       "8           00015            1            0.00002   \n",
       "9           000dm            1            0.00002   \n",
       "10            001            5            0.00010   \n",
       "11            002            1            0.00002   \n",
       "12         003830            1            0.00002   \n",
       "13            006            1            0.00002   \n",
       "14           0069            1            0.00002   \n",
       "15            007           73            0.00086   \n",
       "16           0079            2            0.00004   \n",
       "17         007the            1            0.00002   \n",
       "18           0080            4            0.00006   \n",
       "19           0083            3            0.00006   \n",
       "\n",
       "    Tasa de aparici√≥n positivas  Tasa de aparici√≥n negativas  \n",
       "0                       0.00316                      0.00420  \n",
       "1                       0.00780                      0.01012  \n",
       "2                       0.00008                      0.00000  \n",
       "3                       0.00000                      0.00004  \n",
       "4                       0.00000                      0.00004  \n",
       "5                       0.00000                      0.00004  \n",
       "6                       0.00000                      0.00008  \n",
       "7                       0.00004                      0.00000  \n",
       "8                       0.00000                      0.00004  \n",
       "9                       0.00000                      0.00004  \n",
       "10                      0.00000                      0.00020  \n",
       "11                      0.00004                      0.00000  \n",
       "12                      0.00004                      0.00000  \n",
       "13                      0.00004                      0.00000  \n",
       "14                      0.00000                      0.00004  \n",
       "15                      0.00136                      0.00036  \n",
       "16                      0.00008                      0.00000  \n",
       "17                      0.00004                      0.00000  \n",
       "18                      0.00012                      0.00000  \n",
       "19                      0.00012                      0.00000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auxDf = pd.DataFrame()\n",
    "auxDf['Palabra'] = vectorizerTotal.get_feature_names_out()\n",
    "auxDf['Apariciones'] = matrizApariciones.sum(axis=0).tolist()[0]\n",
    "auxDf['Tasa de aparici√≥n'] = matrizSiAparece.sum(axis=0) / len(reviews['review_es'])\n",
    "\n",
    "auxDfPos = pd.DataFrame()\n",
    "auxDfPos['Palabra'] = vectorizerPos.get_feature_names_out()\n",
    "auxDfPos['Tasa de aparici√≥n positivas'] = matrizSiAparecePos.sum(axis=0) / len(reviewsPos)\n",
    "\n",
    "auxDfNeg = pd.DataFrame()\n",
    "auxDfNeg['Palabra'] = vectorizerNeg.get_feature_names_out()\n",
    "auxDfNeg['Tasa de aparici√≥n negativas'] = matrizSiApareceNeg.sum(axis=0) / len(reviewsNeg)\n",
    "\n",
    "# Unir los dos DataFrames en uno solo\n",
    "auxDf = pd.merge(auxDf, auxDfPos, on=['Palabra'], how='outer')\n",
    "auxDf = pd.merge(auxDf, auxDfNeg, on=['Palabra'], how='outer')\n",
    "\n",
    "# Rellenar los valores NaN con 0\n",
    "auxDf.fillna(0, inplace=True)\n",
    "\n",
    "auxDf.head(20)\n",
    "\n",
    "# Tasa de positividad\n",
    "# (TP - TN) / TT = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo (A PARTIR DE ACA NO ESTA HECHO :C)\n",
    "\n",
    "Primero se ve cu√°l es el mejor tipo de clasificador para el modelo, se prueba con Bernoulli, Multinomial y Gaussiano. Luego se optimizan sus hiperpar√°metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_x = reviews['review_es'].copy()\n",
    "reviews_y = reviews['sentimiento'].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(reviews_x, reviews_y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    MultinomialNB(),\n",
    "    ComplementNB(),\n",
    "    BernoulliNB(),\n",
    "]\n",
    "\n",
    "vectorizers = [\n",
    "    CountVectorizer(),\n",
    "    TfidfVectorizer()\n",
    "]\n",
    "\n",
    "for v in vectorizers:\n",
    "    for c in classifiers:\n",
    "        model = make_pipeline(v, c)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        predicted_categories = model.predict(x_test)\n",
    "\n",
    "        print(\"Para\", v, \",\", c, \"la precision es\", round(accuracy_score(y_test, predicted_categories), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis del mejor modelo entrenado\n",
    "\n",
    "Se obtuvo que el mejor modelo es un CountVectorizer con clasificador multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bool = (y_train == 'positivo').astype(int)\n",
    "y_train_pred_bool = (y_train_pred == 'positivo').astype(int)\n",
    "y_test_bool = (y_test == 'positivo').astype(int)\n",
    "y_test_pred_bool = (y_test_pred == 'positivo').astype(int)\n",
    "\n",
    "train_score = f1_score(y_train_bool.values, y_train_pred_bool)\n",
    "test_score = f1_score(y_test_bool.values, y_test_pred_bool)\n",
    "\n",
    "print(\"Matriz de confusi√≥n de los datos de prueba:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, cmap='Blues',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_train_bool, y_train_pred_bool)\n",
    "recall=recall_score(y_train_bool, y_train_pred_bool)\n",
    "f1=f1_score(y_train_bool, y_train_pred_bool)\n",
    "precision=precision_score(y_train_bool, y_train_pred_bool)\n",
    "\n",
    "print(\"C√°lculo de las m√©tricas en el conjunto de entrenamiento\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "accuracy=accuracy_score(y_test_bool,y_test_pred_bool)\n",
    "recall=recall_score(y_test_bool,y_test_pred_bool)\n",
    "f1=f1_score(y_test_bool,y_test_pred_bool)\n",
    "precision=precision_score(y_test_bool,y_test_pred_bool)\n",
    "\n",
    "print(\"\\nC√°lculo de las m√©tricas en el conjunto de pruebas\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"mnb\", MultinomialNB())])\n",
    "\n",
    "params_grid = {\n",
    "        'tfidf__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "        'tfidf__max_features': [1000, 10000, 100000],\n",
    "        'mnb__alpha': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "scorer_fn = make_scorer(f1_score, pos_label='positivo')\n",
    "kfoldcv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred, pos_label='positivo')\n",
    "print(\"Par√°metros:\", gridcv.best_params_, \"\\nF1 score: \", round(score, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "y_train_bool = (y_train == 'positivo').astype(int)\n",
    "y_train_pred_bool = (y_train_pred == 'positivo').astype(int)\n",
    "y_test_bool = (y_test == 'positivo').astype(int)\n",
    "y_test_pred_bool = (y_pred == 'positivo').astype(int)\n",
    "\n",
    "train_score = f1_score(y_train_bool.values, y_train_pred_bool)\n",
    "test_score = f1_score(y_test_bool.values, y_test_pred_bool)\n",
    "\n",
    "print(\"Matriz de confusi√≥n de los datos de prueba:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, cmap='Blues',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_train_bool, y_train_pred_bool)\n",
    "recall=recall_score(y_train_bool, y_train_pred_bool)\n",
    "f1=f1_score(y_train_bool, y_train_pred_bool)\n",
    "precision=precision_score(y_train_bool, y_train_pred_bool)\n",
    "\n",
    "print(\"C√°lculo de las m√©tricas en el conjunto de entrenamiento\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "accuracy=accuracy_score(y_test_bool,y_test_pred_bool)\n",
    "recall=recall_score(y_test_bool,y_test_pred_bool)\n",
    "f1=f1_score(y_test_bool,y_test_pred_bool)\n",
    "precision=precision_score(y_test_bool,y_test_pred_bool)\n",
    "\n",
    "print(\"\\nC√°lculo de las m√©tricas en el conjunto de pruebas\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nueva Hip√≥tesis: Filtrar los reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este TP no fue necesario analizar y filtrar la base de datos antes de crear el Bayes Naive model. Pero se pens√≥ cuantificar qu√© tan negativo o positivo son los reviews y luego modificar el dataset seg√∫n eso. Habr√≠a dos maneras de filtrarlo: solo tomando los reviews m√°s extremos o solamente tomar los mas neutrales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe una librer√≠a llamada TextBlob para intentar lograr esto. El an√°lisis de sentimiento de TextBlob implica el uso de un modelo de aprendizaje autom√°tico previamente entrenado para asignar una puntuaci√≥n de polaridad a un fragmento de texto determinado. El modelo eval√∫a las palabras y frases del texto y proporciona una puntuaci√≥n num√©rica que indica la positividad o negatividad del sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "reviews_hip = reviews.copy()\n",
    "\n",
    "def quantify_reviews(review):\n",
    "    analysis = TextBlob(review)\n",
    "    return analysis.sentiment.polarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funci√≥n quantify_reviews() agarra cada review, lo transforma en un objeto TextBlob y analiza el sentimiento del review, devolviendo un float entre -1 y 1 donde 1 es extremadamente positivo y -1 se extremadamente negativo.\n",
    "\n",
    "Ahora se deben encontrar los thresholds optimos para probar nuestra hip√≥tesis y saber qu√© reviews eliminar antes de entrenar al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_hip['score'] = reviews_hip['review_es'].apply(quantify_reviews)\n",
    "\n",
    "pos_threshold = 0.1\n",
    "neg_threshold = -0.305\n",
    "filtered_data = reviews_hip[((reviews_hip['score'] < pos_threshold) & (reviews_hip['score'] > neg_threshold))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_hip_x = filtered_data['review_es'].copy()\n",
    "reviews_hip_y = filtered_data['sentimiento'].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(reviews_hip_x, reviews_hip_y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bool = (y_train == 'positivo').astype(int)\n",
    "y_train_pred_bool = (y_train_pred == 'positivo').astype(int)\n",
    "y_test_bool = (y_test == 'positivo').astype(int)\n",
    "y_test_pred_bool = (y_test_pred == 'positivo').astype(int)\n",
    "\n",
    "train_score = f1_score(y_train_bool.values, y_train_pred_bool)\n",
    "test_score = f1_score(y_test_bool.values, y_test_pred_bool)\n",
    "\n",
    "print(\"Matriz de confusi√≥n de los datos de prueba:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, cmap='Blues',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_train_bool, y_train_pred_bool)\n",
    "recall=recall_score(y_train_bool, y_train_pred_bool)\n",
    "f1=f1_score(y_train_bool, y_train_pred_bool)\n",
    "precision=precision_score(y_train_bool, y_train_pred_bool)\n",
    "\n",
    "print(\"C√°lculo de las m√©tricas en el conjunto de entrenamiento\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "accuracy=accuracy_score(y_test_bool,y_test_pred_bool)\n",
    "recall=recall_score(y_test_bool,y_test_pred_bool)\n",
    "f1=f1_score(y_test_bool,y_test_pred_bool)\n",
    "precision=precision_score(y_test_bool,y_test_pred_bool)\n",
    "\n",
    "print(\"\\nC√°lculo de las m√©tricas en el conjunto de pruebas\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de un probar diferentes thesholds manualmente y probar ambas maneras de filtrar, nos dio mejores resultados tomar los reviews m√°s neutrales con un threshold de -0.305 < x < 0.1. Intentaremos probar con valores m√°s cercanos a este threshold para conseguir un mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theshold = (0,0)\n",
    "best_score = 0\n",
    "\n",
    "\n",
    "for pos_threshold in np.arange(0.095, 0.1055, 0.0025):\n",
    "    for neg_threshold in np.arange(-0.315, -0.295, 0.0025):\n",
    "        #print(\"Threshold: \" + str(neg_threshold) + \" < x < \" + str(pos_threshold))\n",
    "\n",
    "        filtered_data = reviews_hip[((reviews_hip['score'] < pos_threshold) & (reviews_hip['score'] > neg_threshold))]\n",
    "\n",
    "        reviews_hip_x = filtered_data['review_es'].copy()\n",
    "        reviews_hip_y = filtered_data['sentimiento'].copy()\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(reviews_hip_x, reviews_hip_y, test_size=0.30, random_state=0)\n",
    "        \n",
    "        model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "\n",
    "        y_train_bool = (y_train == 'positivo').astype(int)\n",
    "        y_train_pred_bool = (y_train_pred == 'positivo').astype(int)\n",
    "        y_test_bool = (y_test == 'positivo').astype(int)\n",
    "        y_test_pred_bool = (y_test_pred == 'positivo').astype(int)\n",
    "\n",
    "        f1=f1_score(y_test_bool,y_test_pred_bool)\n",
    "\n",
    "        #print(\"\\nC√°lculo de las m√©tricas en el conjunto de pruebas\")\n",
    "        #print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "        #print(\"-----------------------------------------------------\")\n",
    "\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_theshold = [neg_threshold, pos_threshold]\n",
    "\n",
    "\n",
    "print(\"Best threshold: \" + str(best_theshold[0]) + \" < x < \" + str(round(best_theshold[1], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = reviews_hip[((reviews_hip['score'] < best_theshold[1]) & (reviews_hip['score'] > best_theshold[0]))]\n",
    "\n",
    "reviews_hip_x = filtered_data['review_es'].copy()\n",
    "reviews_hip_y = filtered_data['sentimiento'].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(reviews_hip_x, reviews_hip_y, test_size=0.30, random_state=0)\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_bool = (y_train == 'positivo').astype(int)\n",
    "y_train_pred_bool = (y_train_pred == 'positivo').astype(int)\n",
    "y_test_bool = (y_test == 'positivo').astype(int)\n",
    "y_test_pred_bool = (y_test_pred == 'positivo').astype(int)\n",
    "\n",
    "train_score = f1_score(y_train_bool.values, y_train_pred_bool)\n",
    "test_score = f1_score(y_test_bool.values, y_test_pred_bool)\n",
    "\n",
    "print(\"Matriz de confusi√≥n de los datos de prueba:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, cmap='Blues',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_train_bool, y_train_pred_bool)\n",
    "recall=recall_score(y_train_bool, y_train_pred_bool)\n",
    "f1=f1_score(y_train_bool, y_train_pred_bool)\n",
    "precision=precision_score(y_train_bool, y_train_pred_bool)\n",
    "\n",
    "print(\"C√°lculo de las m√©tricas en el conjunto de entrenamiento\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "accuracy=accuracy_score(y_test_bool,y_test_pred_bool)\n",
    "recall=recall_score(y_test_bool,y_test_pred_bool)\n",
    "f1=f1_score(y_test_bool,y_test_pred_bool)\n",
    "precision=precision_score(y_test_bool,y_test_pred_bool)\n",
    "\n",
    "print(\"\\nC√°lculo de las m√©tricas en el conjunto de pruebas\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hip√≥tesis + Grid Search\n",
    "\n",
    "Le aplico un Grid Search a nuestro nuevo dataset filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = reviews_hip[((reviews_hip['score'] < best_theshold[1]) & (reviews_hip['score'] > best_theshold[0]))]\n",
    "\n",
    "reviews_hip_x = filtered_data['review_es'].copy()\n",
    "reviews_hip_y = filtered_data['sentimiento'].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(reviews_hip_x, reviews_hip_y, test_size=0.30, random_state=0)\n",
    "\n",
    "\n",
    "model = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"mnb\", MultinomialNB())])\n",
    "\n",
    "params_grid = {\n",
    "        'tfidf__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "        'tfidf__max_features': [1000, 10000, 100000],\n",
    "        'mnb__alpha': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "scorer_fn = make_scorer(f1_score, pos_label='positivo')\n",
    "kfoldcv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred, pos_label='positivo')\n",
    "print(\"Par√°metros:\", gridcv.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "y_train_bool = (y_train == 'positivo').astype(int)\n",
    "y_train_pred_bool = (y_train_pred == 'positivo').astype(int)\n",
    "y_test_bool = (y_test == 'positivo').astype(int)\n",
    "y_test_pred_bool = (y_pred == 'positivo').astype(int)\n",
    "\n",
    "train_score = f1_score(y_train_bool.values, y_train_pred_bool)\n",
    "test_score = f1_score(y_test_bool.values, y_test_pred_bool)\n",
    "\n",
    "print(\"Matriz de confusi√≥n de los datos de prueba:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, cmap='Blues',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_train_bool, y_train_pred_bool)\n",
    "recall=recall_score(y_train_bool, y_train_pred_bool)\n",
    "f1=f1_score(y_train_bool, y_train_pred_bool)\n",
    "precision=precision_score(y_train_bool, y_train_pred_bool)\n",
    "\n",
    "print(\"C√°lculo de las m√©tricas en el conjunto de entrenamiento\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "accuracy=accuracy_score(y_test_bool,y_test_pred_bool)\n",
    "recall=recall_score(y_test_bool,y_test_pred_bool)\n",
    "f1=f1_score(y_test_bool,y_test_pred_bool)\n",
    "precision=precision_score(y_test_bool,y_test_pred_bool)\n",
    "\n",
    "print(\"\\nC√°lculo de las m√©tricas en el conjunto de pruebas\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicci√≥n del conjunto test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['ID'] = test['ID'].values\n",
    "predictions['sentimiento'] = model.predict(test['review_es'])\n",
    "\n",
    "predictions.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
