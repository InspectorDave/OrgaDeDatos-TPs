{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://i.ytimg.com/vi/Wm8ftqDZUVk/maxresdefault.jpg\" alt=\"FIUBA\" width=\"25%\"/>\n",
    "  </p>\n",
    "  \n",
    "# **Trabajo Pr치ctico 2: Cr칤ticas Cinematogr치ficas**\n",
    "### **Grupo**: 11 - Los Pandas 游냪\n",
    "### **Cuatrimestre**: 2췈C 2023\n",
    "### **Corrector**: Mateo Suster\n",
    "### **Integrantes**:\n",
    "- ### 106861 - Labollita, Francisco\n",
    "- ### 102312 - Mundani Vegega, Ezequiel\n",
    "- ###  97263 - Otegui, Mat칤as I침aki"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('train_clean.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaci칩n del bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerTotal = CountVectorizer(strip_accents='unicode', dtype='uint16')\n",
    "vectorizerTotal.fit_transform(reviews['review_es'])\n",
    "\n",
    "# Primeros 20 elementos\n",
    "print(vectorizerTotal.get_feature_names_out()[:20])\n",
    "# Elementos del medio\n",
    "print(vectorizerTotal.get_feature_names_out()[10000:10020])\n",
    "# 칔ltimos 20 elementos\n",
    "print(vectorizerTotal.get_feature_names_out()[-20:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que varias \"palabras\" ser치n n칰meros, algunas tendr치n s칤mbolos no pertenecientes al alfabeto espa침ol y tambi칠n se comprueba que est치n palabras espa침olas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering del bag of words\n",
    "\n",
    "En primer lugar, siendo que todas las palabras que inician una oraci칩n empiezan en may칰scula, se har치 que todas las letras de palabras con una sola may칰scula sean transformadas a min칰sculas. De tal manera que en el siguiente ejemplo, las dos variaciones de hermosa sean una misma palabra: \"Hermosa pel칤cula\" y \"Esta pel칤cula es hermosa\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizApariciones = vectorizerTotal.fit_transform(reviews['review_es'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizSiAparece = matrizApariciones.toarray()\n",
    "matrizApariciones = matrizApariciones.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizSiAparece[matrizSiAparece > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame()\n",
    "words_df['Palabra'] = vectorizerTotal.get_feature_names_out()\n",
    "words_df['Apariciones Totales'] = matrizApariciones.sum(axis=0).tolist() #Cu치ntas veces aparece la palabra\n",
    "words_df['Apariciones'] = matrizSiAparece.sum(axis=0).tolist()           #En cu치ntas reviews aparece la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cuentan en cu치ntas reviews positivas aparece cada palabra\n",
    "listaAparicionesPositivas = np.zeros(shape=len(matrizSiAparece[0])).astype('int32')\n",
    "for i in range(reviews.shape[0]):\n",
    "    if (reviews.iloc[i]['sentimiento'] == 'positivo'):\n",
    "        listaAparicionesPositivas += matrizSiAparece[i]\n",
    "\n",
    "#Se cuentan en cu치ntas reviews negativas aparece cada palabra\n",
    "listaAparicionesNegativas = np.zeros(shape=len(matrizSiAparece[0])).astype('int32')\n",
    "for i in range(reviews.shape[0]):\n",
    "    if (reviews.iloc[i]['sentimiento'] == 'negativo'):\n",
    "        listaAparicionesNegativas += matrizSiAparece[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df['Apariciones positivas'] = listaAparicionesPositivas\n",
    "words_df['Apariciones negativas'] = listaAparicionesNegativas\n",
    "words_df['Fracci칩n apariciones positivas'] = words_df['Apariciones positivas'] / words_df['Apariciones']\n",
    "words_df['Fracci칩n apariciones negativas'] = words_df['Apariciones negativas'] / words_df['Apariciones']\n",
    "words_df['Tasa de positividad'] = (words_df['Apariciones positivas'] - words_df['Apariciones negativas']) / words_df['Apariciones']\n",
    "words_df.sort_values(by='Apariciones', inplace=True, ascending=False)\n",
    "words_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se entrena un m칩delo posible de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    reviews['review_es'], reviews['sentimiento'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear una matriz de t칠rminos de documento utilizando CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "x_train_counts = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Entrenar el modelo de Random Forest\n",
    "model = RandomForestClassifier(max_features='sqrt',\n",
    "                             random_state=2,\n",
    "                             n_jobs=-1,\n",
    "                             criterion=\"entropy\",\n",
    "                             n_estimators=50)\n",
    "\n",
    "model.fit(x_train_counts, y_train)\n",
    "\n",
    "# Transformar los datos de prueba y hacer predicciones\n",
    "x_test_counts = vectorizer.transform(x_test)\n",
    "y_test_pred = model.predict(x_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Matriz de confusi칩n de los datos de prueba\")\n",
    "sns.heatmap(tabla, cmap='GnBu', annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"C치lculo de las m칠tricas en el conjunto de pruebas\")\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "print(\"Recall: \"+str(recall))\n",
    "print(\"Precision: \"+str(precision))\n",
    "print(\"F1 Score: \"+str(f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se buscan los hiperpar치metros con GridSearch CV\n",
    "\n",
    "Se realiz칩 una busqueda de los mejores par치metros con el m칠todo GridSearchCV proporcionando varios par치metros posibles basados en lo estudiado en las clases pr치cticas.\n",
    "\n",
    "Se obtuvo que los mejores hiperpar치metros (utilizando el F1 score como m칠trica) para este caso son:\n",
    "\n",
    "- *min_samples_leaf* = $X$\n",
    "- Criterio = XXXX\n",
    "- *min_samples_split* = X\n",
    "- *n_estimators* = XX\n",
    "\n",
    "Logrando un F1 score de 0.XXX, mayor en comparaci칩n al primer 치rbol obtenido que fue de 0.XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = RandomForestClassifier(\n",
    "    max_features='sqrt', oob_score=True, random_state=1, n_jobs=-1)\n",
    "\n",
    "param_grid = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\n",
    "              \"min_samples_split\": [2, 4, 10, 12, 16],\n",
    "              \"n_estimators\": [10, 20, 50]}\n",
    "\n",
    "\n",
    "metricas = ['accuracy', 'f1', 'roc_auc']\n",
    "\n",
    "gs_multimetrica = GridSearchCV(estimator=rf_cv,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring=metricas,\n",
    "                               refit=False,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "gs_multimetrica_fit = gs_multimetrica.fit(X=x_train, y=y_train)\n",
    "\n",
    "params_elegidos = gs_multimetrica_fit.cv_results_[\n",
    "    'params'][np.argmax(gs_multimetrica_fit.cv_results_['mean_test_accuracy'])]\n",
    "params_elegidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [key for key in gs_multimetrica_fit.cv_results_.keys()\n",
    "          if (\"mean_test\" in key)]\n",
    "\n",
    "for k in labels:\n",
    "    plt.plot(gs_multimetrica_fit.cv_results_[\n",
    "             k], linestyle='--', linewidth=0.8, marker='o', markersize=2)\n",
    "    x_linea = np.argmax(gs_multimetrica_fit.cv_results_[k])\n",
    "    plt.axvline(x_linea, linestyle='--', linewidth=0.8, color='grey')\n",
    "\n",
    "plt.xlabel(\"modelo\", fontsize=10)\n",
    "plt.ylabel(\"m칠trica\", fontsize=10)\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_multimetrica = RandomForestClassifier(criterion='gini',\n",
    "                                          min_samples_leaf=1,\n",
    "                                          min_samples_split=4,\n",
    "                                          n_estimators=50,\n",
    "                                          oob_score=True,\n",
    "                                          random_state=2,\n",
    "                                          n_jobs=-1)\n",
    "\n",
    "model = rfc_multimetrica.fit(X=x_train, y=y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de confusi칩n de los datos de prueba\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, cmap='Blues', annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "recall = recall_score(y_train, y_train_pred)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "precision = precision_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"C치lculo de las m칠tricas en el conjunto de entrenamiento\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicci칩n del conjunto test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_clean.csv')\n",
    "\n",
    "x_test_counts = vectorizer.transform(test_df['review_es'])\n",
    "y_pred_test = model.predict(x_test_counts)\n",
    "\n",
    "test_df['sentimiento'] = y_pred_test\n",
    "\n",
    "test_df.drop(\"review_es\", axis=1, inplace=True)\n",
    "test_df.to_csv('sample_solution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
