{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://i.ytimg.com/vi/Wm8ftqDZUVk/maxresdefault.jpg\" alt=\"FIUBA\" width=\"25%\"/>\n",
    "  </p>\n",
    "  \n",
    "# **Trabajo Pr√°ctico 2: Cr√≠ticas Cinematogr√°ficas**\n",
    "### **Grupo**: 11 - Los Pandas üêº\n",
    "### **Cuatrimestre**: 2¬∫C 2023\n",
    "### **Corrector**: Mateo Suster\n",
    "### **Integrantes**:\n",
    "- ### 106861 - Labollita, Francisco\n",
    "- ### 102312 - Mundani Vegega, Ezequiel\n",
    "- ###  97263 - Otegui, Mat√≠as I√±aki"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaci√≥n del bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '00000' '00000000000' '0000000000001' '00000001' '00001'\n",
      " '0001' '00015' '000dm' '001' '002' '003830' '006' '0069' '007' '0079'\n",
      " '007the' '0080' '0083']\n",
      "['antisocial' 'antisociales' 'antiste' 'antisunciados' 'antit'\n",
      " 'antitabaco' 'antitanque' 'antiterroristas' 'antitesis' 'antitetico'\n",
      " 'antithesis' 'antithetical' 'antitica' 'antitm' 'antitreideros'\n",
      " 'antitrust' 'antivirus' 'antiwar' 'antm' 'antoina']\n",
      "['zyuranger' 'zz' 'zzzz' 'zzzzip' 'zzzzz' 'zzzzzzzzz' 'zzzzzzzzzzzzzz'\n",
      " 'zzzzzzzzzzzzzzzzz' 'zzzzzzzzzzzzzzzzzzzz' 'zzzzzzzzzzzzzzzzzzzzz'\n",
      " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz'\n",
      " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz' '√¶bler' '√¶on' '√¶sthetic'\n",
      " '√∏stbye' '√æo' '√æorleifsson' '◊ô◊í◊ê◊ú' '◊õ◊®◊û◊ï◊ü']\n"
     ]
    }
   ],
   "source": [
    "vectorizerTotal = CountVectorizer(strip_accents='unicode', dtype='uint16')\n",
    "vectorizerTotal.fit_transform(reviews['review_es'])\n",
    "\n",
    "# Primeros 20 elementos\n",
    "print(vectorizerTotal.get_feature_names_out()[:20])\n",
    "# Elementos del medio\n",
    "print(vectorizerTotal.get_feature_names_out()[10000:10020])\n",
    "# √öltimos 20 elementos\n",
    "print(vectorizerTotal.get_feature_names_out()[-20:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que varias \"palabras\" ser√°n n√∫meros, algunas tendr√°n s√≠mbolos no pertenecientes al alfabeto espa√±ol y tambi√©n se comprueba que est√°n palabras espa√±olas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering del bag of words\n",
    "\n",
    "En primer lugar, siendo que todas las palabras que inician una oraci√≥n empiezan en may√∫scula, se har√° que todas las letras de palabras con una sola may√∫scula sean transformadas a min√∫sculas. De tal manera que en el siguiente ejemplo, las dos variaciones de hermosa sean una misma palabra: \"Hermosa pel√≠cula\" y \"Esta pel√≠cula es hermosa\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizApariciones = vectorizerTotal.fit_transform(reviews['review_es'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizSiAparece = matrizApariciones.toarray()\n",
    "matrizApariciones = matrizApariciones.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizSiAparece[matrizSiAparece > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame()\n",
    "words_df['Palabra'] = vectorizerTotal.get_feature_names_out()\n",
    "words_df['Apariciones Totales'] = matrizApariciones.sum(axis=0).tolist() #Cu√°ntas veces aparece la palabra\n",
    "words_df['Apariciones'] = matrizSiAparece.sum(axis=0).tolist()           #En cu√°ntas reviews aparece la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cuentan en cu√°ntas reviews positivas aparece cada palabra\n",
    "listaAparicionesPositivas = np.zeros(shape=len(matrizSiAparece[0])).astype('int32')\n",
    "for i in range(reviews.shape[0]):\n",
    "    if (reviews.iloc[i]['sentimiento'] == 'positivo'):\n",
    "        listaAparicionesPositivas += matrizSiAparece[i]\n",
    "\n",
    "#Se cuentan en cu√°ntas reviews negativas aparece cada palabra\n",
    "listaAparicionesNegativas = np.zeros(shape=len(matrizSiAparece[0])).astype('int32')\n",
    "for i in range(reviews.shape[0]):\n",
    "    if (reviews.iloc[i]['sentimiento'] == 'negativo'):\n",
    "        listaAparicionesNegativas += matrizSiAparece[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Apariciones Totales</th>\n",
       "      <th>Apariciones</th>\n",
       "      <th>Apariciones positivas</th>\n",
       "      <th>Apariciones negativas</th>\n",
       "      <th>Fracci√≥n apariciones positivas</th>\n",
       "      <th>Fracci√≥n apariciones negativas</th>\n",
       "      <th>Tasa de positividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41364</th>\n",
       "      <td>de</td>\n",
       "      <td>661907</td>\n",
       "      <td>47992</td>\n",
       "      <td>23949</td>\n",
       "      <td>24043</td>\n",
       "      <td>0.499021</td>\n",
       "      <td>0.500979</td>\n",
       "      <td>-0.001959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128119</th>\n",
       "      <td>que</td>\n",
       "      <td>395365</td>\n",
       "      <td>47245</td>\n",
       "      <td>23501</td>\n",
       "      <td>23744</td>\n",
       "      <td>0.497428</td>\n",
       "      <td>0.502572</td>\n",
       "      <td>-0.005143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93125</th>\n",
       "      <td>la</td>\n",
       "      <td>405160</td>\n",
       "      <td>47147</td>\n",
       "      <td>23496</td>\n",
       "      <td>23651</td>\n",
       "      <td>0.498356</td>\n",
       "      <td>0.501644</td>\n",
       "      <td>-0.003288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55382</th>\n",
       "      <td>en</td>\n",
       "      <td>276429</td>\n",
       "      <td>45938</td>\n",
       "      <td>22882</td>\n",
       "      <td>23056</td>\n",
       "      <td>0.498106</td>\n",
       "      <td>0.501894</td>\n",
       "      <td>-0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53511</th>\n",
       "      <td>el</td>\n",
       "      <td>253915</td>\n",
       "      <td>45037</td>\n",
       "      <td>22381</td>\n",
       "      <td>22656</td>\n",
       "      <td>0.496947</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>-0.006106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162711</th>\n",
       "      <td>una</td>\n",
       "      <td>170883</td>\n",
       "      <td>43530</td>\n",
       "      <td>21815</td>\n",
       "      <td>21715</td>\n",
       "      <td>0.501149</td>\n",
       "      <td>0.498851</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58627</th>\n",
       "      <td>es</td>\n",
       "      <td>183244</td>\n",
       "      <td>43210</td>\n",
       "      <td>21708</td>\n",
       "      <td>21502</td>\n",
       "      <td>0.502384</td>\n",
       "      <td>0.497616</td>\n",
       "      <td>0.004767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162707</th>\n",
       "      <td>un</td>\n",
       "      <td>186195</td>\n",
       "      <td>43041</td>\n",
       "      <td>21390</td>\n",
       "      <td>21651</td>\n",
       "      <td>0.496968</td>\n",
       "      <td>0.503032</td>\n",
       "      <td>-0.006064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111087</th>\n",
       "      <td>no</td>\n",
       "      <td>145805</td>\n",
       "      <td>42253</td>\n",
       "      <td>19918</td>\n",
       "      <td>22335</td>\n",
       "      <td>0.471398</td>\n",
       "      <td>0.528602</td>\n",
       "      <td>-0.057203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60252</th>\n",
       "      <td>esta</td>\n",
       "      <td>119728</td>\n",
       "      <td>40952</td>\n",
       "      <td>20067</td>\n",
       "      <td>20885</td>\n",
       "      <td>0.490013</td>\n",
       "      <td>0.509987</td>\n",
       "      <td>-0.019975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Palabra  Apariciones Totales  Apariciones  Apariciones positivas  \\\n",
       "41364       de               661907        47992                  23949   \n",
       "128119     que               395365        47245                  23501   \n",
       "93125       la               405160        47147                  23496   \n",
       "55382       en               276429        45938                  22882   \n",
       "53511       el               253915        45037                  22381   \n",
       "162711     una               170883        43530                  21815   \n",
       "58627       es               183244        43210                  21708   \n",
       "162707      un               186195        43041                  21390   \n",
       "111087      no               145805        42253                  19918   \n",
       "60252     esta               119728        40952                  20067   \n",
       "\n",
       "        Apariciones negativas  Fracci√≥n apariciones positivas  \\\n",
       "41364                   24043                        0.499021   \n",
       "128119                  23744                        0.497428   \n",
       "93125                   23651                        0.498356   \n",
       "55382                   23056                        0.498106   \n",
       "53511                   22656                        0.496947   \n",
       "162711                  21715                        0.501149   \n",
       "58627                   21502                        0.502384   \n",
       "162707                  21651                        0.496968   \n",
       "111087                  22335                        0.471398   \n",
       "60252                   20885                        0.490013   \n",
       "\n",
       "        Fracci√≥n apariciones negativas  Tasa de positividad  \n",
       "41364                         0.500979            -0.001959  \n",
       "128119                        0.502572            -0.005143  \n",
       "93125                         0.501644            -0.003288  \n",
       "55382                         0.501894            -0.003788  \n",
       "53511                         0.503053            -0.006106  \n",
       "162711                        0.498851             0.002297  \n",
       "58627                         0.497616             0.004767  \n",
       "162707                        0.503032            -0.006064  \n",
       "111087                        0.528602            -0.057203  \n",
       "60252                         0.509987            -0.019975  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df['Apariciones positivas'] = listaAparicionesPositivas\n",
    "words_df['Apariciones negativas'] = listaAparicionesNegativas\n",
    "words_df['Fracci√≥n apariciones positivas'] = words_df['Apariciones positivas'] / words_df['Apariciones']\n",
    "words_df['Fracci√≥n apariciones negativas'] = words_df['Apariciones negativas'] / words_df['Apariciones']\n",
    "words_df['Tasa de positividad'] = (words_df['Apariciones positivas'] - words_df['Apariciones negativas']) / words_df['Apariciones']\n",
    "words_df.sort_values(by='Apariciones', inplace=True, ascending=False)\n",
    "words_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se entrena un modelo b√°sico de XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se transforman los positivos en 1 y los negativos en 0\n",
    "# Transformar los valores de reviews['sentimiento'] a 1 y 0\n",
    "reviews['sentimiento'] = reviews['sentimiento'].apply(lambda x: 1 if x == 'positivo' else 0)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    reviews['review_es'], reviews['sentimiento'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear una matriz de t√©rminos de documento utilizando CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "x_train_counts = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Entrenar el modelo de Random Forest\n",
    "model = xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ezequ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84      4961\n",
      "           1       0.84      0.86      0.85      5039\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.85      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_counts, y_train)\n",
    "\n",
    "# Transformar los datos de prueba y hacer predicciones\n",
    "x_test_counts = vectorizer.transform(x_test)\n",
    "y_pred = model.predict(x_test_counts)\n",
    "\n",
    "# Imprimir el informe de clasificaci√≥n\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicci√≥n del conjunto test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "#Transformo todas las letras a min√∫scula\n",
    "test_df['review_es'] = test_df['review_es'].str.lower()\n",
    "\n",
    "x_test_counts = vectorizer.transform(test_df['review_es'])\n",
    "y_pred_test = model.predict(x_test_counts)\n",
    "\n",
    "test_df['sentimiento'] = y_pred_test\n",
    "test_df['sentimiento'] = test_df['sentimiento'].apply(lambda x: 'positivo' if x == 1 else 'negativo')\n",
    "\n",
    "test_df.drop(\"review_es\", axis=1, inplace=True)\n",
    "test_df.to_csv('sample_solution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
