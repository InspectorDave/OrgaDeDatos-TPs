{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28-KL5kLo58g"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://i.ytimg.com/vi/Wm8ftqDZUVk/maxresdefault.jpg\" alt=\"FIUBA\" width=\"33%\"/>\n",
        "  </p>\n",
        "  \n",
        "# **Trabajo Práctico 1: Reservas de Hotel**\n",
        "### **Checkpoint**: 3\n",
        "### **Grupo**: 11 - Los Pandas\n",
        "### **Cuatrimestre**: 2ºC 2023\n",
        "### **Corrector**: Mateo\n",
        "### **Integrantes**:\n",
        "### 103456 - Labollita, Francisco\n",
        "### 102312 - Mundani Vegega, Ezequiel\n",
        "###  97263 - Otegui, Matías Iñaki"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZb17i6fo58p"
      },
      "source": [
        "# Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KxbGDRquo58r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import calendar\n",
        "#import dtreeviz\n",
        "import warnings\n",
        "\n",
        "#modelos y métricas\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score,f1_score#, precision_recall_curve, roc_curve,\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#preprocesamiento\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)\n",
        "from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Aclaración:\n",
        "# Hay un warning que puede llegar a aparecer que es debido a una actualización interna de Seaborn que será deprecada, para solucionarlo hay que modificar el código de python\n",
        "# directamente (lo cual no es una buena práctica).\n",
        "# La función en concreto se va a seguir utilizando, por lo que no afecta a nuestro código en sí, si no al comportamiento interno de dicha función.\n",
        "# Se propone ignorar dicho warninig, ya que se solucionará en la próxima versión de Python\n",
        "# En el siguiente enlace se puede encontrar más información:\n",
        "# https://github.com/ultralytics/ultralytics/issues/4729\n",
        "# https://github.com/mwaskom/seaborn/issues/3462\n",
        "#\n",
        "# se puede ignorar descomentando las siguientes líneas\n",
        "\n",
        "warnings.filterwarnings('ignore', 'is_categorical_dtype is deprecated')\n",
        "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
        "\n",
        "# o bien otra solución (más elegante), es obtener dicha actualización corriendo esta línea:\n",
        "# pip install -U ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Be8i4kOMo58v"
      },
      "outputs": [],
      "source": [
        "hotels_df = pd.read_csv('hotels_train.csv')\n",
        "hotels_df_backup = hotels_df.copy()\n",
        "\n",
        "#Eliminación de columnas irrelevantes\n",
        "hotels_df_mod = hotels_df.drop(['arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'children', 'company', 'adr', 'id'], axis=1)\n",
        "\n",
        "#Eliminación de filas con valores nulos\n",
        "hotels_df_mod = hotels_df_mod.dropna(subset=['country', 'distribution_channel', 'market_segment'])\n",
        "\n",
        "#Eliminación de filas con outliers\n",
        "hotels_df_mod = hotels_df_mod.drop(hotels_df_mod[hotels_df_mod['adults'] > 4].index)\n",
        "\n",
        "#Agent sin definir es un valor válido, por lo que se reemplaza por Undefined\n",
        "hotels_df_mod['agent'] = hotels_df_mod['agent'].astype(str)\n",
        "hotels_df_mod['agent'] = hotels_df_mod['agent'].replace('nan', 'Undefined')\n",
        "\n",
        "#Se crea la columna que dice si se asignó la habitación pedida\n",
        "hotels_df_mod = hotels_df_mod.rename(columns={'reserved_room_type': 'room_type_match'})\n",
        "\n",
        "hotels_df_mod.loc[hotels_df_mod['room_type_match'] == hotels_df_mod['assigned_room_type'], 'room_type_match'] = True\n",
        "hotels_df_mod.loc[hotels_df_mod['room_type_match'] != hotels_df_mod['assigned_room_type'], 'room_type_match'] = False\n",
        "hotels_df_mod['room_type_match'] = hotels_df_mod['room_type_match'].astype(bool)\n",
        "\n",
        "#Se normalizan los valores de las columnas numéricas cuantitativas\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "for col in hotels_df_mod.select_dtypes(include=[np.number, \"int64\", \"float64\"]).columns:\n",
        "    hotels_df_mod[col] = scaler.fit_transform(hotels_df_mod[[col]])\n",
        "\n",
        "#One-hot encoding para las columnas categóricas\n",
        "hotels_df_mod = pd.get_dummies(hotels_df_mod, columns=[\"hotel\",\n",
        "    \"arrival_date_month\", \"meal\", \"country\", \"market_segment\", \"distribution_channel\", \"assigned_room_type\",\n",
        "    \"deposit_type\", \"customer_type\", \"agent\" ], drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1elZDUZo58w",
        "outputId": "ec06a578-8ca4-46a9-dc66-74eb9b430b35"
      },
      "outputs": [],
      "source": [
        "df_y = hotels_df_mod['is_canceled'].copy()\n",
        "df_x = hotels_df_mod.drop(['is_canceled'], axis=1)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.30, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAL9Blz1mHV"
      },
      "source": [
        "## Optimización de hiperparámetros\n",
        "\n",
        "Se prueban distintos Kernels (Linear, RBF, Polynomial y Sigmoid). Se notó que realizar un gridsearch entre los 4 kernels tomaba mucho más tiempo que compararlos directamente con un for, así que se realizó el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBy3tlwD19qI",
        "outputId": "a88f6abd-70bd-43d7-83f5-b4b48ac8699e"
      },
      "outputs": [],
      "source": [
        "kernel_list = ['linear', 'rbf', 'sigmoid', 'poly']\n",
        "\n",
        "for kernel_type in kernel_list:\n",
        "  svm_model = SVC(kernel=kernel_type, cache_size=1024)\n",
        "\n",
        "  svm_model.fit(x_train, y_train)\n",
        "\n",
        "  y_pred = svm_model.predict(x_test)\n",
        "  score = f1_score(y_test, y_pred)\n",
        "  print(kernel_type, \"F1 score: \", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hiperparametros: {'kernel': 'linear'} F1-Score: 0.8144170436175571\n"
          ]
        }
      ],
      "source": [
        "svm_model = SVC(cache_size=1024)\n",
        "\n",
        "params_grid = {'kernel':['linear']}#, 'poly', 'rbf', 'sigmoid']}\n",
        "\n",
        "scorer_fn = make_scorer(f1_score)\n",
        "\n",
        "gridcv = GridSearchCV(estimator=svm_model,\n",
        "                      param_grid = params_grid,\n",
        "                      scoring=scorer_fn,\n",
        "                      n_jobs=4\n",
        "                      )\n",
        "\n",
        "model = gridcv.fit(x_train,y_train)\n",
        "\n",
        "print(\"Hiperparametros:\",gridcv.best_params_, \"F1-Score:\",gridcv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "svm_model = SVC(cache_size=1024)\n",
        "\n",
        "params_grid = {'kernel':['linear']}#, 'poly', 'rbf', 'sigmoid']}\n",
        "\n",
        "scorer_fn = make_scorer(f1_score)\n",
        "\n",
        "gridcv = GridSearchCV(estimator=svm_model,\n",
        "                      param_grid = params_grid,\n",
        "                      scoring=scorer_fn,\n",
        "                      n_jobs=-1\n",
        "                      )\n",
        "\n",
        "model = gridcv.fit(x_train,y_train)\n",
        "\n",
        "print(\"Hiperparametros:\",gridcv.best_params_, \"F1-Score:\",gridcv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_dBPjFvG3Yz"
      },
      "outputs": [],
      "source": [
        "svm_model = SVC()\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['poly'], #possiblemente agregar rbf kernel (descomentar gamma param)\n",
        "    'degree': [2, 3, 4],\n",
        "    #'gamma': [0.1, 1, 10],\n",
        "    'coef0': [-1, 0, 1]\n",
        "}\n",
        "\n",
        "scorer_fn = make_scorer(f1_score)\n",
        "\n",
        "randomcv = RandomizedSearchCV(svm_model, param_grid, n_iter=5, scoring=scorer_fn, cv=5)\n",
        "model = randomcv.fit(x_train,y_train)\n",
        "\n",
        "print(\"Hiperparametros:\",randomcv.best_params_, \"F1-Score:\",randomcv.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicción del test armado a partir de hotels_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SVC(kernel='poly')\n",
        "model.fit(x_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=model.predict(x_test)\n",
        "y_pred\n",
        "\n",
        "print (\"Fracción de aciertos:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tabla=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cálculo de las métricas en el conjunto de evaluación\n",
        "accuracy=accuracy_score(y_test,y_pred)\n",
        "recall=recall_score(y_test,y_pred)\n",
        "f1=f1_score(y_test,y_pred)\n",
        "precision=precision_score(y_test,y_pred)\n",
        "\n",
        "print(\"Accuracy: \"+str(accuracy))\n",
        "print(\"Recall: \"+str(recall))\n",
        "print(\"Precision: \"+str(precision))\n",
        "print(\"f1 score: \"+str(f1))\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOZ0r8J7_yFE"
      },
      "source": [
        "## Predicción sobre hotels_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwuL1htt_xwl"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('hotels_test.csv')\n",
        "\n",
        "test_df_mod = test_df.copy()\n",
        "\n",
        "# renombrar columna del dataframe de reserved_room_type a room_type_match\n",
        "test_df_mod = test_df_mod.rename(columns={'reserved_room_type': 'room_type_match'})\n",
        "\n",
        "test_df_mod.loc[test_df_mod['room_type_match'] == test_df_mod['assigned_room_type'], 'room_type_match'] = True\n",
        "test_df_mod.loc[test_df_mod['room_type_match'] != test_df_mod['assigned_room_type'], 'room_type_match'] = False\n",
        "test_df_mod['room_type_match'] = test_df_mod['room_type_match'].astype(bool)\n",
        "\n",
        "test_df_mod['agent'] = test_df_mod['agent'].astype(str)\n",
        "\n",
        "id_backup = test_df_mod[['id']].copy()\n",
        "\n",
        "test_df_mod = test_df_mod.drop(['arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'children', 'company', 'adr', 'id'], axis=1)\n",
        "test_df_mod = test_df_mod.drop(['reservation_status_date'], axis='columns')\n",
        "\n",
        "\n",
        "#Se normalizan los valores de las columnas numéricas cuantitativas\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "for col in test_df_mod.select_dtypes(include=[np.number, \"int64\", \"float64\"]).columns:\n",
        "    test_df_mod[col] = scaler.fit_transform(test_df_mod[[col]])\n",
        "\n",
        "test_df_mod = pd.get_dummies(test_df_mod, columns=[\"hotel\", \"arrival_date_month\", \"meal\", \"country\", \"market_segment\", \"distribution_channel\", \"assigned_room_type\", \"deposit_type\", \"customer_type\", \"agent\" ], drop_first=True)\n",
        "\n",
        "#Se crean las columnas que están en el df para entrenar pero no en el df a precedir\n",
        "for col in df_x.columns:\n",
        "    if col not in test_df_mod.columns:\n",
        "        test_df_mod[col] = False\n",
        "\n",
        "#Se eliminan las columnas que están en el df para predecir pero no en el df para entrenar\n",
        "for col in test_df_mod.columns:\n",
        "    if col not in df_x.columns:\n",
        "        test_df_mod = test_df_mod.drop(columns=[col])\n",
        "\n",
        "test_df_mod = test_df_mod.reindex(sorted(test_df_mod.columns), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG4k0sZBQSkD"
      },
      "outputs": [],
      "source": [
        "#Se realiza una predicción sobre test utilizando el modelo\n",
        "y_pred = model.predict(test_df_mod)\n",
        "\n",
        "predictions = pd.DataFrame()\n",
        "\n",
        "predictions['id'] = id_backup['id'].values\n",
        "predictions['is_canceled'] = y_pred.astype(int)\n",
        "\n",
        "predictions.to_csv('entrega.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
