{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://i.ytimg.com/vi/Wm8ftqDZUVk/maxresdefault.jpg\" alt=\"FIUBA\" width=\"33%\"/>\n",
    "  </p>\n",
    "  \n",
    "# **Trabajo Práctico 1: Reservas de Hotel**\n",
    "### **Checkpoint**: 3\n",
    "### **Grupo**: 11 - Los Pandas\n",
    "### **Cuatrimestre**: 2ºC 2023\n",
    "### **Corrector**: Mateo Suster\n",
    "### **Integrantes**:\n",
    "### 103456 - Labollita, Francisco\n",
    "### 102312 - Mundani Vegega, Ezequiel\n",
    "###  97263 - Otegui, Matías Iñaki"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import calendar\n",
    "#import dtreeviz\n",
    "import warnings\n",
    "\n",
    "#modelos y métricas\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score,f1_score#, precision_recall_curve, roc_curve,\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#preprocesamiento\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings('ignore', 'is_categorical_dtype is deprecated')\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_df = pd.read_csv('hotels_train.csv')\n",
    "hotels_df_backup = hotels_df.copy()\n",
    "\n",
    "#Eliminación de columnas irrelevantes\n",
    "hotels_df_mod = hotels_df.drop(['arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'children', 'company', 'adr', 'id'], axis=1)\n",
    "\n",
    "#Eliminación de filas con valores nulos\n",
    "hotels_df_mod = hotels_df_mod.dropna(subset=['country', 'distribution_channel', 'market_segment'])\n",
    "\n",
    "#Eliminación de filas con outliers\n",
    "hotels_df_mod = hotels_df_mod.drop(hotels_df_mod[hotels_df_mod['adults'] > 4].index)\n",
    "\n",
    "#Agent sin definir es un valor válido, por lo que se reemplaza por Undefined\n",
    "hotels_df_mod['agent'] = hotels_df_mod['agent'].astype(str)\n",
    "hotels_df_mod['agent'] = hotels_df_mod['agent'].replace('nan', 'Undefined')\n",
    "\n",
    "#Se crea la columna que dice si se asignó la habitación pedida\n",
    "hotels_df_mod = hotels_df_mod.rename(columns={'reserved_room_type': 'room_type_match'})\n",
    "\n",
    "hotels_df_mod.loc[hotels_df_mod['room_type_match'] == hotels_df_mod['assigned_room_type'], 'room_type_match'] = True\n",
    "hotels_df_mod.loc[hotels_df_mod['room_type_match'] != hotels_df_mod['assigned_room_type'], 'room_type_match'] = False\n",
    "hotels_df_mod['room_type_match'] = hotels_df_mod['room_type_match'].astype(bool)\n",
    "\n",
    "#Se normalizan los valores de las columnas numéricas cuantitativas\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for col in hotels_df_mod.select_dtypes(include=[np.number, \"int64\", \"float64\"]).columns:\n",
    "    hotels_df_mod[col] = scaler.fit_transform(hotels_df_mod[[col]])\n",
    "\n",
    "#One-hot encoding para las columnas categóricas\n",
    "hotels_df_mod = pd.get_dummies(hotels_df_mod, columns=[\"hotel\",\n",
    "    \"arrival_date_month\", \"meal\", \"country\", \"market_segment\", \"distribution_channel\", \"assigned_room_type\",\n",
    "    \"deposit_type\", \"customer_type\", \"agent\" ], drop_first=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encogimiento del dataset\n",
    "\n",
    "Siendo que SVM es un método costoso, se decide probar utilizando un dataset de entrenamiento reducido. En caso que el rendimiento no sea tan diferente, se optimizarán los hiperparámetros utilizando este dataset reducido y luego se entrenará al modelo utilizando todo el split de train.\n",
    "\n",
    "Además se decidió utilizar pocos folds para el cross validation para reducir el tiempo que se tardaba. El rendimiento fue demasiado afectado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = hotels_df_mod.drop(['is_canceled'], axis=1)\n",
    "df_y = hotels_df_mod['is_canceled'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros: {'kernel': 'rbf'} \n",
      "F1 score:  0.833\n"
     ]
    }
   ],
   "source": [
    "x_train_grande, x_test_grande, y_train, y_test = train_test_split(df_x, df_y, train_size= 0.7, test_size=0.30, random_state=2)\n",
    "\n",
    "svm_model = SVC(cache_size=1024, random_state = 2)\n",
    "\n",
    "params_grid = {'kernel':['linear', 'rbf']}\n",
    "\n",
    "scorer_fn = make_scorer(f1_score)\n",
    "kfoldcv = StratifiedKFold(n_splits=2)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=svm_model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv,\n",
    "                      n_jobs=-1\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train_grande,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_grande)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Parámetros:\", model.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros: {'kernel': 'rbf'} \n",
      "F1 score:  0.818\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, train_size= 0.2, test_size=0.30, random_state=2)\n",
    "\n",
    "svm_model = SVC(cache_size=1024, random_state = 2)\n",
    "\n",
    "params_grid = {'kernel':['linear', 'rbf']}\n",
    "\n",
    "scorer_fn = make_scorer(f1_score)\n",
    "kfoldcv = StratifiedKFold(n_splits=2)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=svm_model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv,\n",
    "                      n_jobs=-1\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Parámetros:\", model.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siendo que el rendimiento al utilizar un dataset del doble de tamaño es solo 1% mejor, se considera que es buena idea trabajar con el dataset reducido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros\n",
    "\n",
    "Siendo que los distintos kernels utilizan distintos parámetros, no tiene sentido hacer una comparación todos contra todos porque habrá iteraciones que al fin y al cambo sean iguales, por lo que se realizará un grid search para cada kernel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: lineal\n",
    "\n",
    "Hiperparámetros:\n",
    "\n",
    "* C : es un parámetro de regularización, debe ser estrictamente positivo.\n",
    "\n",
    "Dado que la fuerza de la regularización es inversamente proporcional a C\n",
    "- un valor pequeño significa que el margen se calcula utilizando muchas o todas las observaciones alrededor de la línea de separación (más regularización).\n",
    "- un valor grande significa que el margen se calcula sobre observaciones cercanas a la línea de separación (menos regularización)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel lineal, parámetros: {'C': 50} \n",
      "F1 score:  0.805\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', cache_size=1024, random_state = 2)\n",
    "\n",
    "params_grid = { \n",
    "                'C':[1, 5, 10, 50, 100, 500, 1000]\n",
    "                }\n",
    "\n",
    "scorer_fn = make_scorer(f1_score)\n",
    "kfoldcv = StratifiedKFold(n_splits=2)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=svm_model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv,\n",
    "                      n_jobs=-1\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Kernel lineal, parámetros:\", gridcv.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: radial\n",
    "\n",
    "Hiperparámetros:\n",
    "\n",
    "* C : es un parámetro de regularización.\n",
    "\n",
    "* gamma: define cuánta influencia tiene un solo ejemplo de entrenamiento. Cuanto mayor sea, más cerca deberán estar otros ejemplos para verse afectados  \n",
    "\n",
    "La elección adecuada de C y gamma resulta fundamental para el rendimiento de la SVM. Es recomendable utilizar GridSearchCV con C y gamma espaciado exponencialmente para elegir buenos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel radial, parámetros: {'C': 10, 'gamma': 'scale'} \n",
      "F1 score:  0.829\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', cache_size=1024, random_state = 2)\n",
    "\n",
    "params_grid = { \n",
    "                'C':[1, 5, 10, 50, 100, 500, 1000],\n",
    "                'gamma':['scale', 'auto', 1, 5, 10, 50, 100, 500, 1000]\n",
    "                }\n",
    "\n",
    "scorer_fn = make_scorer(f1_score)\n",
    "kfoldcv = StratifiedKFold(n_splits=2)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=svm_model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv,\n",
    "                      n_jobs=-1\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Kernel radial, parámetros:\", gridcv.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: polinómico\n",
    "\n",
    "Hiperparametros:\n",
    "\n",
    "* C : Parámetro de regularización.\n",
    "\n",
    "* degree: Grado de la función kernel polinomial ('poly'). Ignorado por todos los demás núcleos\n",
    "\n",
    "* gamma: define cuánta influencia tiene un solo ejemplo de entrenamiento. Cuanto más grande es, más cerca deben estar otros ejemplos para verse afectados.\n",
    "\n",
    "* coef0 : se corresponde con el parámetro r de la ecucacion del kernel\n",
    "$K(a, b) =  (a \\cdot b + r) ^ d$ ($d$ es el grado del polinomio).\n",
    "\n",
    "La elección adecuada de C y gamma es fundamental para el rendimiento de la SVM. Se recomienda usar GridSearchCV con C y gamma espaciado exponencialmente para elegir buenos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel polinómico, parámetros: {'C': 50, 'coef0': 5, 'degree': 4, 'gamma': 'auto'} \n",
      "F1 score:  0.829\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='poly', cache_size=1024, random_state = 2)\n",
    "\n",
    "params_grid = { \n",
    "                'C': [10, 50, 100],\n",
    "                'gamma': ['scale', 'auto', 1, 5],\n",
    "                'degree': [1, 2, 3, 4],\n",
    "                'coef0': [0, 1, 5]\n",
    "                }\n",
    "\n",
    "scorer_fn = make_scorer(f1_score)\n",
    "kfoldcv = StratifiedKFold(n_splits=2)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=svm_model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv,\n",
    "                      n_jobs=-1\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Kernel polinómico, parámetros:\", gridcv.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: sigmoide\n",
    "\n",
    "* C : Parámetro de regularización.\n",
    "\n",
    "* degree: Grado de la función kernel polinomial ('poly'). Ignorado por todos los demás núcleos\n",
    "\n",
    "* gamma: define cuánta influencia tiene un solo ejemplo de entrenamiento. Cuanto más grande es, más cerca deben estar otros ejemplos para verse afectados.\n",
    "\n",
    "* coef0 : se corresponde con el parámetro r de la ecucacion del kernel\n",
    "$K(a, b) =  (a \\cdot b + r) ^ d$ ($d$ es el grado del polinomio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel sigmoide, parámetros: {'C': 100, 'coef0': 0, 'degree': 1, 'gamma': 'auto'} \n",
      "F1 score:  0.795\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='sigmoid', cache_size=1024, random_state = 2)\n",
    "\n",
    "params_grid = { \n",
    "                'C': [10, 50, 100],\n",
    "                'gamma': ['scale', 'auto', 1, 5],\n",
    "                'degree': [1, 2, 3, 4],\n",
    "                'coef0': [0, 1, 5, 10]\n",
    "                }\n",
    "\n",
    "scorer_fn = make_scorer(f1_score)\n",
    "kfoldcv = StratifiedKFold(n_splits=2)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=svm_model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv,\n",
    "                      n_jobs=-1\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Kernel sigmoide, parámetros:\", gridcv.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros del kernel radial\n",
    "\n",
    "Siendo que la optimización de hiperparámetros para cada tipo de kernel es costosa, se optimizarán únicamente los del radial, que junto con el polinómico fueron los que devolvieron mejores resultados luego de esa optimización inicial. Esta elección se debe principalmente a la diferencia de tiempo de ejecución entre el polinómico y el radial, siendo el primero mucho más costoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel radial, parámetros: {'C': 9} \n",
      "F1 score:  0.83\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', gamma='scale', cache_size=1024, random_state = 2)\n",
    "\n",
    "params_grid = { \n",
    "                'C':list(range(5, 50, 1)),\n",
    "                }\n",
    "\n",
    "scorer_fn = make_scorer(f1_score)\n",
    "kfoldcv = StratifiedKFold(n_splits=2)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=svm_model,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv,\n",
    "                      n_jobs=6\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Kernel radial, parámetros:\", gridcv.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo con el dataset de train completo\n",
    "\n",
    "Habiendo obtenido los mejores hiperparámetros para ese conjunto reducido, ahora se decide entrenar el modelo con el conjunto completo de train, utilizando los hiperparámetros obtenidos. Es cierto que hubiese sido mejor entrenar el modelo con el conjunto completo de train y luego optimizar los hiperparámetros, pero se decidió hacerlo de esta manera para reducir el tiempo de ejecución, siendo que por ejemplo, para el kernel polinómico, para cada combinación de hiperparámetros se tardaban 7 minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score sobre el set de entrenamiento: 0.883\n",
      "F1-Score sobre el set de prueba: 0.842\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', gamma='scale', C=9, cache_size=1024, random_state = 2)\n",
    "\n",
    "model = svm_model.fit(x_train_grande,y_train)\n",
    "\n",
    "y_train_pred = model.predict(x_train_grande)\n",
    "y_test_pred = model.predict(x_test_grande)\n",
    "\n",
    "train_score = f1_score(y_train, y_train_pred)\n",
    "test_score = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"F1-Score sobre el set de entrenamiento:\", round(train_score, 3))\n",
    "print(\"F1-Score sobre el set de prueba:\", round(test_score, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción del test armado a partir de hotels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Ezequiel\\Desktop\\Universidad\\2023_2\\Organización de Datos\\TP1\\repositorio\\7506R-2C2023-GRUPO11\\7506R_TP1_GRUPO11_CHP3_ENTREGA_SVM.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/Ezequiel/Desktop/Universidad/2023_2/Organizaci%C3%B3n%20de%20Datos/TP1/repositorio/7506R-2C2023-GRUPO11/7506R_TP1_GRUPO11_CHP3_ENTREGA_SVM.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tabla\u001b[39m=\u001b[39mconfusion_matrix(y_test, y_test_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Ezequiel/Desktop/Universidad/2023_2/Organizaci%C3%B3n%20de%20Datos/TP1/repositorio/7506R-2C2023-GRUPO11/7506R_TP1_GRUPO11_CHP3_ENTREGA_SVM.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMatriz de confusión de los datos de prueba\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Ezequiel/Desktop/Universidad/2023_2/Organizaci%C3%B3n%20de%20Datos/TP1/repositorio/7506R-2C2023-GRUPO11/7506R_TP1_GRUPO11_CHP3_ENTREGA_SVM.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sns\u001b[39m.\u001b[39mheatmap(tabla,cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGnBu\u001b[39m\u001b[39m'\u001b[39m,annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mg\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "tabla=confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Matriz de confusión de los datos de prueba\")\n",
    "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8623615239124561\n",
      "Recall: 0.8642995065436602\n",
      "Precision: 0.8627262019488168\n",
      "f1 score: 0.863512137613204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.86      0.86      9183\n",
      "         1.0       0.86      0.86      0.86      9322\n",
      "\n",
      "    accuracy                           0.86     18505\n",
      "   macro avg       0.86      0.86      0.86     18505\n",
      "weighted avg       0.86      0.86      0.86     18505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_train, y_train_pred)\n",
    "recall=recall_score(y_train, y_train_pred)\n",
    "f1=f1_score(y_train, y_train_pred)\n",
    "precision=precision_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Cálculo de las métricas en el conjunto de entrenamiento\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_test,y_test_pred)\n",
    "recall=recall_score(y_test,y_test_pred)\n",
    "f1=f1_score(y_test,y_test_pred)\n",
    "precision=precision_score(y_test,y_test_pred)\n",
    "\n",
    "print(\"Cálculo de las métricas en el conjunto de pruebas\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de hotels_test\n",
    "\n",
    "Se modifica el dataset de test de manera similar al de train, para que el modelo obtenido pueda ser aplicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('hotels_test.csv')\n",
    "\n",
    "test_df_mod = test_df.copy()\n",
    "\n",
    "#Se guarda el id de cada fila para luego poder identificarla\n",
    "id_backup = test_df_mod[['id']].copy()\n",
    "\n",
    "#Se cambia la columna reserved_room_type por room_type_match\n",
    "test_df_mod = test_df_mod.rename(columns={'reserved_room_type': 'room_type_match'})\n",
    "\n",
    "test_df_mod.loc[test_df_mod['room_type_match'] == test_df_mod['assigned_room_type'], 'room_type_match'] = True\n",
    "test_df_mod.loc[test_df_mod['room_type_match'] != test_df_mod['assigned_room_type'], 'room_type_match'] = False\n",
    "test_df_mod['room_type_match'] = test_df_mod['room_type_match'].astype(bool)\n",
    "\n",
    "#Agent sin definir es un valor válido, por lo que se reemplaza por Undefined\n",
    "test_df_mod['agent'] = test_df_mod['agent'].astype(str)\n",
    "test_df_mod['agent'] = test_df_mod['agent'].replace('nan', 'Undefined')\n",
    "\n",
    "#Transformación de variables numéricas a booleanas \n",
    "test_df_mod['required_car_parking_spaces'] = test_df_mod['required_car_parking_spaces'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['required_car_parking_spaces'] = test_df_mod['required_car_parking_spaces'].astype(bool)\n",
    "\n",
    "test_df_mod['days_in_waiting_list'] = test_df_mod['days_in_waiting_list'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['days_in_waiting_list'] = test_df_mod['days_in_waiting_list'].astype(bool)\n",
    "\n",
    "test_df_mod['babies'] = test_df_mod['babies'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['babies'] = test_df_mod['babies'].astype(bool)\n",
    "\n",
    "test_df_mod['previous_cancellations'] = test_df_mod['previous_cancellations'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['previous_cancellations'] = test_df_mod['previous_cancellations'].astype(bool)\n",
    "\n",
    "test_df_mod['total_of_special_requests'] = test_df_mod['total_of_special_requests'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['total_of_special_requests'] = test_df_mod['total_of_special_requests'].astype(bool)\n",
    "\n",
    "test_df_mod['previous_bookings_not_canceled'] = test_df_mod['previous_bookings_not_canceled'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['previous_bookings_not_canceled'] = test_df_mod['previous_bookings_not_canceled'].astype(bool)\n",
    "\n",
    "test_df_mod['booking_changes'] = test_df_mod['booking_changes'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['booking_changes'] = test_df_mod['booking_changes'].astype(bool)\n",
    "\n",
    "test_df_mod = test_df_mod.drop(['arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'children', 'company', 'adr', 'id'], axis=1)\n",
    "test_df_mod = test_df_mod.drop(['reservation_status_date'], axis='columns') #Esta es la columna que no debería estar en el dataset de test\n",
    "\n",
    "#Se normalizan los valores de las columnas numéricas cuantitativas\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for col in test_df_mod.select_dtypes(include=[np.number, \"int64\", \"float64\"]).columns:\n",
    "    test_df_mod[col] = scaler.fit_transform(test_df_mod[[col]])\n",
    "\n",
    "#One-hot encoding para las columnas categóricas\n",
    "test_df_mod = pd.get_dummies(test_df_mod, columns=[\"hotel\", \"arrival_date_month\", \"meal\", \"country\", \"market_segment\", \"distribution_channel\", \"assigned_room_type\", \"deposit_type\", \"customer_type\", \"agent\" ], drop_first=True)\n",
    "\n",
    "#Se crean las columnas que están en el df para entrenar pero no en el df a predecir\n",
    "for col in df_x.columns:\n",
    "    if col not in test_df_mod.columns:\n",
    "        test_df_mod[col] = False\n",
    "\n",
    "#Se eliminan las columnas que están en el df para predecir pero no en el df para entrenar\n",
    "for col in test_df_mod.columns:\n",
    "    if col not in df_x.columns:\n",
    "        test_df_mod = test_df_mod.drop(columns=[col])\n",
    "\n",
    "#Se ordenan las columnas\n",
    "test_df_mod = test_df_mod.reindex(sorted(test_df_mod.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se realiza una predicción sobre test utilizando el modelo\n",
    "y_pred = model.predict(test_df_mod)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "predictions['id'] = id_backup['id'].values\n",
    "predictions['is_canceled'] = y_pred.astype(int)\n",
    "\n",
    "predictions.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
