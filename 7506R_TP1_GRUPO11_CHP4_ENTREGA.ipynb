{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://i.ytimg.com/vi/Wm8ftqDZUVk/maxresdefault.jpg\" alt=\"FIUBA\" width=\"33%\"/>\n",
    "  </p>\n",
    "  \n",
    "# **Trabajo Práctico 1: Reservas de Hotel**\n",
    "### **Checkpoint**: 4\n",
    "### **Grupo**: 11 - Los Pandas\n",
    "### **Cuatrimestre**: 2ºC 2023\n",
    "### **Corrector**: Mateo\n",
    "### **Integrantes**:\n",
    "### 103456 - Labollita, Francisco\n",
    "### 102312 - Mundani Vegega, Ezequiel\n",
    "###  97263 - Otegui, Matías Iñaki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales\n",
    "\n",
    "### Carga inicial de dependencias y datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import calendar\n",
    "#import dtreeviz\n",
    "import warnings\n",
    "\n",
    "#modelos y métricas\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score,f1_score#, precision_recall_curve, roc_curve,\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#preprocesamiento\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "##KFOLD CV Random Search para buscar el mejor arbol (los mejores atributos, hiperparametros,etc)\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Import Keras and Tensor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#Random Seed\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "warnings.filterwarnings('ignore', 'is_categorical_dtype is deprecated')\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_df = pd.read_csv('hotels_train.csv')\n",
    "hotels_df_backup = hotels_df.copy()\n",
    "\n",
    "#Eliminación de columnas irrelevantes\n",
    "hotels_df_mod = hotels_df.drop(['arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
    "                                'stays_in_week_nights', 'children', 'company', 'adr', 'id'], axis=1)\n",
    "\n",
    "#Eliminación de filas con valores nulos\n",
    "hotels_df_mod = hotels_df_mod.dropna(subset=['country', 'distribution_channel', 'market_segment'])\n",
    "\n",
    "#Transformación de variables numéricas a booleanas (>0 = True, 0 = False)\n",
    "hotels_df_mod['required_car_parking_spaces'] = hotels_df_mod['required_car_parking_spaces'].apply(lambda x: True if x >= 1 else False)\n",
    "hotels_df_mod['required_car_parking_spaces'] = hotels_df_mod['required_car_parking_spaces'].astype(bool)\n",
    "\n",
    "hotels_df_mod['days_in_waiting_list'] = hotels_df_mod['days_in_waiting_list'].apply(lambda x: True if x >= 1 else False)\n",
    "hotels_df_mod['days_in_waiting_list'] = hotels_df_mod['days_in_waiting_list'].astype(bool)\n",
    "\n",
    "hotels_df_mod['babies'] = hotels_df_mod['babies'].apply(lambda x: True if x >= 1 else False)\n",
    "hotels_df_mod['babies'] = hotels_df_mod['babies'].astype(bool)\n",
    "\n",
    "hotels_df_mod['previous_cancellations'] = hotels_df_mod['previous_cancellations'].apply(lambda x: True if x >= 1 else False)\n",
    "hotels_df_mod['previous_cancellations'] = hotels_df_mod['previous_cancellations'].astype(bool)\n",
    "\n",
    "hotels_df_mod['total_of_special_requests'] = hotels_df_mod['total_of_special_requests'].apply(lambda x: True if x >= 1 else False)\n",
    "hotels_df_mod['total_of_special_requests'] = hotels_df_mod['total_of_special_requests'].astype(bool)\n",
    "\n",
    "hotels_df_mod['previous_bookings_not_canceled'] = hotels_df_mod['previous_bookings_not_canceled'].apply(lambda x: True if x >= 1 else False)\n",
    "hotels_df_mod['previous_bookings_not_canceled'] = hotels_df_mod['previous_bookings_not_canceled'].astype(bool)\n",
    "\n",
    "hotels_df_mod['booking_changes'] = hotels_df_mod['booking_changes'].apply(lambda x: True if x >= 1 else False)\n",
    "hotels_df_mod['booking_changes'] = hotels_df_mod['booking_changes'].astype(bool)\n",
    "\n",
    "#Eliminación de filas con outliers\n",
    "hotels_df_mod = hotels_df_mod.drop(hotels_df_mod[hotels_df_mod['adults'] > 4].index)\n",
    "\n",
    "#Agent sin definir es un valor válido, por lo que se reemplaza por Undefined\n",
    "hotels_df_mod['agent'] = hotels_df_mod['agent'].astype(str)\n",
    "hotels_df_mod['agent'] = hotels_df_mod['agent'].replace('nan', 'Undefined')\n",
    "\n",
    "#Arrival_date_year se pasa a string\n",
    "hotels_df_mod['arrival_date_year'] = hotels_df_mod['arrival_date_year'].astype(str)\n",
    "\n",
    "#Se crea la columna que dice si se asignó la habitación pedida\n",
    "hotels_df_mod = hotels_df_mod.rename(columns={'reserved_room_type': 'room_type_match'})\n",
    "\n",
    "hotels_df_mod.loc[hotels_df_mod['room_type_match'] == hotels_df_mod['assigned_room_type'], 'room_type_match'] = True\n",
    "hotels_df_mod.loc[hotels_df_mod['room_type_match'] != hotels_df_mod['assigned_room_type'], 'room_type_match'] = False\n",
    "hotels_df_mod['room_type_match'] = hotels_df_mod['room_type_match'].astype(bool)\n",
    "\n",
    "#Se normalizan los valores de las columnas numéricas cuantitativas\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for col in hotels_df_mod.select_dtypes(include=[np.number, \"int64\", \"float64\"]).columns:\n",
    "    hotels_df_mod[col] = scaler.fit_transform(hotels_df_mod[[col]])\n",
    "\n",
    "#One-hot encoding para las columnas categóricas\n",
    "hotels_df_mod = pd.get_dummies(hotels_df_mod, columns=[\"hotel\",\n",
    "    \"arrival_date_month\", \"meal\", \"country\", \"market_segment\", \"distribution_channel\", \"assigned_room_type\",\n",
    "    \"deposit_type\", \"customer_type\", \"agent\", 'arrival_date_year'], drop_first=True)\n",
    "\n",
    "#Se transforman las columnas booleanas en float\n",
    "bool_columns = hotels_df_mod.select_dtypes(include=['bool'])\n",
    "for column in bool_columns.columns:\n",
    "    hotels_df_mod[column] = hotels_df_mod[column].astype('float64')\n",
    "\n",
    "hotels_df_mod = hotels_df_mod.reindex(sorted(hotels_df_mod.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento inicial del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = hotels_df_mod.drop(['is_canceled'], axis=1)\n",
    "df_y = hotels_df_mod['is_canceled'].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, train_size= 0.7, test_size=0.30, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 4016      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4097 (16.00 KB)\n",
      "Trainable params: 4097 (16.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a simple feedforward neural network\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(8, activation='relu', input_shape=(df_x.columns.size,)),  # Input layer\n",
    "    keras.layers.Dense(8, activation='relu'), \n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8446906208992004\n",
      "F1 Score: <function f1_score at 0x000001978E199F80>\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='nadam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cant_epochs=50\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=cant_epochs, batch_size=32, validation_split=0.3, verbose = False, use_multiprocessing=True)\n",
    "\n",
    "# Evaluate the model on the test dataß\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "print(f'F1 Score: {f1_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Confusion y otras métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train, verbose=False)\n",
    "y_test_pred = model.predict(x_test, verbose=False)\n",
    "\n",
    "binary_predictions_test = (y_test_pred > 0.5).astype(int)\n",
    "binary_predictions_train = (y_train_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score sobre el set de entrenamiento: 0.859\n",
      "F1-Score sobre el set de prueba: 0.843\n"
     ]
    }
   ],
   "source": [
    "train_score = f1_score(y_train, binary_predictions_train)\n",
    "test_score = f1_score(y_test, binary_predictions_test)\n",
    "\n",
    "print(\"F1-Score sobre el set de entrenamiento:\", round(train_score, 3))\n",
    "print(\"F1-Score sobre el set de prueba:\", round(test_score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización mediante Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Híperparametros:\n",
    "- Epochs\n",
    "- Activation\n",
    "- Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sklearn model for the network\n",
    "\n",
    "def create_model(neurons=8, activation_function='relu', l_rate=0.001):\n",
    "\n",
    "    # Create a simple feedforward neural network\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Dense(units=neurons, activation=activation_function, input_shape=(df_x.columns.size,), kernel_regularizer=l2(0.01)),  # Input layer\n",
    "    keras.layers.Dense(units=neurons, activation=activation_function, kernel_regularizer=l2(0.01)), \n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer \n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.SGD(learning_rate=l_rate),\n",
    "      loss='binary_crossentropy',\n",
    "      # metricas para ir calculando en cada iteracion o batch\n",
    "      metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n",
      "/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "45 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/scikeras/wrappers.py\", line 1491, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/scikeras/wrappers.py\", line 760, in fit\n",
      "    self._fit(\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/scikeras/wrappers.py\", line 915, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/scikeras/wrappers.py\", line 852, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/scikeras/wrappers.py\", line 427, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"/var/folders/sx/p4bbsw2947l2kjgww8lxntch0000gn/T/ipykernel_5070/166985700.py\", line 7, in create_model\n",
      "    keras.layers.Dense(units=neurons, activation=activation_function, input_shape=(df_x.columns.size,), kernel_regularizer=l2(0.01)),  # Input layer\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/keras/src/dtensor/utils.py\", line 96, in _wrap_function\n",
      "    init_method(layer_instance, *args, **kwargs)\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/keras/src/layers/core/dense.py\", line 125, in __init__\n",
      "    self.activation = activations.get(activation)\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/keras/src/activations.py\", line 705, in get\n",
      "    return deserialize(identifier, use_legacy_format=use_legacy_format)\n",
      "  File \"/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/keras/src/activations.py\", line 660, in deserialize\n",
      "    raise ValueError(\n",
      "ValueError: Unknown activation function 'lineal' cannot be deserialized.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/franciscolabollita/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.80940232 0.80885095 0.80890563 0.81559287 0.82593407 0.82750436\n",
      " 0.7820238  0.78701775 0.78549535        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros: {'activation_function': 'relu', 'batch_size': 100, 'epochs': 50, 'l_rate': 0.01, 'neurons': 64} \n",
      "F1 score:  0.831\n"
     ]
    }
   ],
   "source": [
    "modelo_cv = KerasClassifier(model=create_model, neurons=8, activation_function='relu', l_rate=0.001, optimizer='nadam', verbose = False, random_state=2)\n",
    "\n",
    "params_grid = {\n",
    "    \n",
    "    'epochs': [50],\n",
    "    'batch_size': [100],\n",
    "    'neurons': [16, 32, 64],\n",
    "    'activation_function':['relu', 'lineal'],\n",
    "    'l_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "scorer_fn = make_scorer(f1_score)\n",
    "kfoldcv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "gridcv = GridSearchCV(estimator=modelo_cv,\n",
    "                      param_grid = params_grid,\n",
    "                      scoring=scorer_fn,\n",
    "                      cv=kfoldcv,\n",
    "                      )\n",
    "\n",
    "model = gridcv.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = f1_score(y_test, y_pred)\n",
    "print(\"Parámetros:\", gridcv.best_params_, \"\\nF1 score: \", round(score, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión de los datos de prueba\n",
      "F1-Score sobre el set de entrenamiento: 0.788\n",
      "F1-Score sobre el set de prueba: 0.782\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "binary_predictions_test = (y_test_pred > 0.5).astype(int)\n",
    "binary_predictions_train = (y_train_pred > 0.5).astype(int)\n",
    "\n",
    "train_score = f1_score(y_train, binary_predictions_train)\n",
    "test_score = f1_score(y_test, binary_predictions_test)\n",
    "\n",
    "print(\"Matriz de confusión de los datos de prueba\")\n",
    "cm = confusion_matrix(y_test, binary_predictions_test)\n",
    "sns.heatmap(cm, cmap='Blues',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "print(\"F1-Score sobre el set de entrenamiento:\", round(train_score, 3))\n",
    "print(\"F1-Score sobre el set de prueba:\", round(test_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cálculo de las métricas en el conjunto de entrenamiento\n",
      "Accuracy:  0.795\n",
      "Recall:  0.763\n",
      "Precision:  0.815\n",
      "F1 score:  0.788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.83      0.80     21559\n",
      "         1.0       0.81      0.76      0.79     21617\n",
      "\n",
      "    accuracy                           0.79     43176\n",
      "   macro avg       0.80      0.79      0.79     43176\n",
      "weighted avg       0.80      0.79      0.79     43176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_train, y_train_pred)\n",
    "recall=recall_score(y_train, y_train_pred)\n",
    "f1=f1_score(y_train, y_train_pred)\n",
    "precision=precision_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Cálculo de las métricas en el conjunto de entrenamiento\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cálculo de las métricas en el conjunto de pruebas\n",
      "Accuracy:  0.789\n",
      "Recall:  0.758\n",
      "Precision:  0.808\n",
      "F1 score:  0.782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.82      0.79      9241\n",
      "         1.0       0.81      0.76      0.78      9264\n",
      "\n",
      "    accuracy                           0.79     18505\n",
      "   macro avg       0.79      0.79      0.79     18505\n",
      "weighted avg       0.79      0.79      0.79     18505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_test_pred)\n",
    "recall=recall_score(y_test,y_test_pred)\n",
    "f1=f1_score(y_test,y_test_pred)\n",
    "precision=precision_score(y_test,y_test_pred)\n",
    "\n",
    "print(\"Cálculo de las métricas en el conjunto de pruebas\")\n",
    "print(\"Accuracy: \", round(accuracy, 3))\n",
    "print(\"Recall: \", round(recall, 3))\n",
    "print(\"Precision: \", round(precision, 3))\n",
    "print(\"F1 score: \", round(f1, 3))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de hotels_test\n",
    "\n",
    "Se modifica el dataset de test de manera similar al de train, para que el modelo obtenido pueda ser aplicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('hotels_test.csv')\n",
    "test_df_mod = test_df.copy()\n",
    "\n",
    "# renombrar columna del dataframe de reserved_room_type a room_type_match\n",
    "test_df_mod = test_df_mod.rename(columns={'reserved_room_type': 'room_type_match'})\n",
    "\n",
    "test_df_mod.loc[test_df_mod['room_type_match'] == test_df_mod['assigned_room_type'], 'room_type_match'] = True\n",
    "test_df_mod.loc[test_df_mod['room_type_match'] != test_df_mod['assigned_room_type'], 'room_type_match'] = False\n",
    "test_df_mod['room_type_match'] = test_df_mod['room_type_match'].astype(bool)\n",
    "\n",
    "test_df_mod['agent'] = test_df_mod['agent'].astype(str)\n",
    "\n",
    "id_backup = test_df_mod[['id']].copy()\n",
    "\n",
    "test_df_mod = test_df_mod.drop(['arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
    "                                'stays_in_week_nights', 'children', 'company', 'adr', 'id'], axis=1)\n",
    "\n",
    "#Arrival_date_year se pasa a string\n",
    "test_df_mod['arrival_date_year'] = test_df_mod['arrival_date_year'].astype(str)\n",
    "\n",
    "#Transformación de variables numéricas a booleanas \n",
    "test_df_mod['required_car_parking_spaces'] = test_df_mod['required_car_parking_spaces'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['required_car_parking_spaces'] = test_df_mod['required_car_parking_spaces'].astype(bool)\n",
    "\n",
    "test_df_mod['days_in_waiting_list'] = test_df_mod['days_in_waiting_list'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['days_in_waiting_list'] = test_df_mod['days_in_waiting_list'].astype(bool)\n",
    "\n",
    "test_df_mod['babies'] = test_df_mod['babies'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['babies'] = test_df_mod['babies'].astype(bool)\n",
    "\n",
    "test_df_mod['previous_cancellations'] = test_df_mod['previous_cancellations'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['previous_cancellations'] = test_df_mod['previous_cancellations'].astype(bool)\n",
    "\n",
    "test_df_mod['total_of_special_requests'] = test_df_mod['total_of_special_requests'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['total_of_special_requests'] = test_df_mod['total_of_special_requests'].astype(bool)\n",
    "\n",
    "test_df_mod['previous_bookings_not_canceled'] = test_df_mod['previous_bookings_not_canceled'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['previous_bookings_not_canceled'] = test_df_mod['previous_bookings_not_canceled'].astype(bool)\n",
    "\n",
    "test_df_mod['booking_changes'] = test_df_mod['booking_changes'].apply(lambda x: True if x >= 1 else False)\n",
    "test_df_mod['booking_changes'] = test_df_mod['booking_changes'].astype(bool)\n",
    "\n",
    "#Se normalizan los valores de las columnas numéricas cuantitativas\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "for col in test_df_mod.select_dtypes(include=[np.number, \"int64\", \"float64\"]).columns:\n",
    "    test_df_mod[col] = scaler.fit_transform(test_df_mod[[col]])\n",
    "\n",
    "#One-hot encoding para las columnas categóricas\n",
    "test_df_mod = pd.get_dummies(test_df_mod, columns=[\"hotel\", \"arrival_date_month\", \"meal\", \"country\",\n",
    "    \"market_segment\",\"distribution_channel\", \"assigned_room_type\", \"deposit_type\", \"customer_type\",\n",
    "    \"agent\", \"arrival_date_year\" ], drop_first=True)\n",
    "\n",
    "#Se crean las columnas que están en el df para entrenar pero no en el df a predecir\n",
    "for col in df_x.columns:\n",
    "    if col not in test_df_mod.columns:\n",
    "        test_df_mod[col] = False\n",
    "\n",
    "#Se eliminan las columnas que están en el df para predecir pero no en el df para entrenar\n",
    "for col in test_df_mod.columns:\n",
    "    if col not in df_x.columns:\n",
    "        test_df_mod = test_df_mod.drop(columns=[col])\n",
    "\n",
    "# Convert the 'bool' columns to 'float64'\n",
    "bool_columns = test_df_mod.select_dtypes(include=['bool'])\n",
    "for column in bool_columns.columns:\n",
    "    test_df_mod[column] = test_df_mod[column].astype('float64')\n",
    "\n",
    "test_df_mod = test_df_mod.reindex(sorted(test_df_mod.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se realiza una predicción sobre test utilizando el modelo\n",
    "y_pred = model.predict(test_df_mod)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "predictions['id'] = id_backup['id'].values\n",
    "predictions['is_canceled'] = y_pred.astype(int)\n",
    "\n",
    "predictions.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
